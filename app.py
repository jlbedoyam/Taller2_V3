import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from scipy.stats import zscore
import numpy as np

# ğŸ”¹ IntegraciÃ³n con LLM
from langchain_groq import ChatGroq
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# ======================
# ESTILOS
# ======================
st.set_page_config(layout="wide", page_title="EDA Interactivo con LLM")

st.markdown("""
    <style>
    .sidebar .sidebar-content {
        background-color: #e6f0ff;
    }
    .block-container {
        max-width: 1200px;
        padding: 2rem;
    }
    </style>
""", unsafe_allow_html=True)

# ======================
# SIDEBAR
# ======================
st.sidebar.title("MenÃº de opciones")
menu = st.sidebar.radio(
    "Selecciona una secciÃ³n:",
    ["Carga de Datos", "EDA", "Asistente LLM", "ğŸ“– DocumentaciÃ³n"]
)

# ======================
# CARGA DE DATOS
# ======================
if menu == "Carga de Datos":
    st.header("ğŸ“‚ Carga de Datos")

    file = st.file_uploader("Sube un archivo CSV", type=["csv"])
    if file:
        df = pd.read_csv(file)
        st.session_state.df = df
        st.success("âœ… Dataset cargado correctamente")
        st.dataframe(df.head())
    else:
        st.info("Por favor, carga un archivo CSV para comenzar.")

# ======================
# EDA
# ======================
elif menu == "EDA" and "df" in st.session_state:
    st.header("ğŸ“Š AnÃ¡lisis Exploratorio de Datos")

    df = st.session_state.df

    # InformaciÃ³n general
    st.subheader("InformaciÃ³n general")
    st.write(df.describe(include="all"))

    # DetecciÃ³n de nulos
    st.subheader("Valores nulos")
    st.write(df.isnull().sum())

    # NormalizaciÃ³n y Z-Score
    st.subheader("Transformaciones")
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()

    if numeric_cols:
        option = st.selectbox("Selecciona una columna numÃ©rica:", numeric_cols)

        if option:
            col_data = df[option].dropna()

            # NormalizaciÃ³n Min-Max
            scaler = MinMaxScaler()
            norm_data = scaler.fit_transform(col_data.values.reshape(-1, 1))

            # Z-Score
            z_scores = zscore(col_data)

            st.write(f"ğŸ“Œ **Columna seleccionada:** {option}")
            st.write("ğŸ”¹ NormalizaciÃ³n Min-Max (primeros 5 valores):", norm_data[:5].flatten())
            st.write("ğŸ”¹ Z-Scores (primeros 5 valores):", z_scores[:5])

            # GrÃ¡fico
            fig, ax = plt.subplots(1, 2, figsize=(12, 4))
            sns.histplot(col_data, ax=ax[0], kde=True)
            ax[0].set_title("DistribuciÃ³n original")
            sns.histplot(norm_data.flatten(), ax=ax[1], kde=True)
            ax[1].set_title("DistribuciÃ³n normalizada")
            st.pyplot(fig)
    else:
        st.warning("âš ï¸ No hay columnas numÃ©ricas disponibles.")

# ======================
# ASISTENTE LLM
# ======================
elif menu == "Asistente LLM" and "df" in st.session_state:
    st.header("ğŸ¤– Asistente LLM sobre tu dataset")

    # --- Persistencia de API Key en la sesiÃ³n ---
    if "groq_api_key" not in st.session_state:
        st.session_state.groq_api_key = None

    # Si ya estÃ¡ guardada, no vuelve a pedirla
    if st.session_state.groq_api_key:
        st.info("ğŸ”‘ API Key cargada en esta sesiÃ³n.")
    else:
        groq_api_key = st.text_input("Ingresa tu API Key de Groq", type="password")
        if groq_api_key:
            st.session_state.groq_api_key = groq_api_key
            st.success("âœ… API Key guardada en esta sesiÃ³n")

    # BotÃ³n para cerrar sesiÃ³n de la API Key
    if st.session_state.groq_api_key:
        if st.button("Cerrar sesiÃ³n de API Key"):
            st.session_state.groq_api_key = None
            st.info("ğŸ”’ API Key eliminada de la sesiÃ³n.")

    # --- Si hay token, inicializamos el modelo ---
    if st.session_state.groq_api_key:
        model = ChatGroq(
            groq_api_key=st.session_state.groq_api_key,
            model_name="llama-3.3-70b-versatile"
        )

        # Prompt Template
        template = """
        Eres un experto en ciencia de datos.
        Dataset cargado con las siguientes columnas: {columns}.
        Resumen estadÃ­stico:
        {stats}

        El usuario pregunta: {question}
        Responde en espaÃ±ol de manera clara y concisa.
        """
        prompt = PromptTemplate(
            input_variables=["columns", "stats", "question"],
            template=template
        )
        chain = LLMChain(llm=model, prompt=prompt)

        # --- Input de pregunta ---
        user_question = st.text_input("Escribe tu pregunta sobre el dataset:")
        if user_question:
            df = st.session_state.df
            columns = ", ".join(df.columns)
            stats = df.describe(include="all").to_string()

            response = chain.run(columns=columns, stats=stats, question=user_question)
            st.markdown("### ğŸ“Œ Respuesta del asistente:")
            st.write(response)
    else:
        st.warning("âš ï¸ Ingresa tu API Key para usar el asistente.")

# ======================
# DOCUMENTACIÃ“N
# ======================
elif menu == "ğŸ“– DocumentaciÃ³n":
    st.header("ğŸ“– DocumentaciÃ³n del Asistente LLM")

    st.markdown("""
    ## ğŸ”¹ DescripciÃ³n
    Este asistente utiliza un **Modelo de Lenguaje de Gran Escala (LLM)** para analizar tu dataset
    y responder preguntas en espaÃ±ol de manera clara y contextualizada.

    ## ğŸ”¹ Arquitectura del modelo
    - **Modelo:** `llama-3.3-70b-versatile`
    - **Proveedor:** [Groq](https://groq.com/) (API ultrarrÃ¡pida para inferencia de LLMs).
    - **IntegraciÃ³n:** Implementada mediante [LangChain](https://www.langchain.com/) y la clase `ChatGroq`.
    - **Prompting:** Se utiliza un `PromptTemplate` que incluye:
        - Columnas del dataset.
        - Resumen estadÃ­stico (`df.describe()`).
        - Pregunta del usuario.

    ## ğŸ”¹ Funcionamiento general
    1. El usuario carga un dataset en la aplicaciÃ³n.
    2. Se solicita (una sola vez por sesiÃ³n) la **API Key de Groq**.
    3. El asistente genera respuestas basadas en:
        - Estructura y estadÃ­sticas del dataset.
        - La pregunta escrita por el usuario.
    4. La respuesta se muestra en lenguaje natural en la aplicaciÃ³n.

    ## ğŸ”¹ Buenas prÃ¡cticas de uso
    - AsegÃºrate de que tu dataset estÃ© limpio antes de hacer preguntas.
    - Usa preguntas claras y directas (ejemplo: *â€œÂ¿CuÃ¡l es la media de la columna ventas por regiÃ³n?â€*).
    - Ten en cuenta que el modelo **no ejecuta cÃ¡lculos adicionales**, solo interpreta la informaciÃ³n que se le pasa.

    ## ğŸ”¹ Limitaciones
    - Depende de la calidad y estructura del dataset cargado.
    - No reemplaza un anÃ¡lisis estadÃ­stico profundo, sino que lo complementa.
    - Requiere conexiÃ³n a internet y una **API Key vÃ¡lida de Groq**.

    ---
    âœ¨ Este mÃ³dulo busca hacer mÃ¡s intuitivo el **AnÃ¡lisis Exploratorio de Datos (EDA)**
    apoyÃ¡ndose en modelos de lenguaje de Ãºltima generaciÃ³n.
    """)
