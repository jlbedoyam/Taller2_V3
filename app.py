import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from langchain_huggingface import HuggingFacePipeline
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM

# -------------------------------
# Configuraci√≥n general
# -------------------------------
st.set_page_config(
    page_title="Taller 2 - An√°lisis de Datos con LLM",
    layout="wide",
)

# -------------------------------
# Funci√≥n para construir el LLM
# -------------------------------
def build_llm(hf_token: str):
    model_name = "meta-llama/Meta-Llama-3-8B-Instruct"

    tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        token=hf_token,
        device_map="auto",
        torch_dtype="auto"
    )

    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=512,
        temperature=0.2,
        top_p=0.9,
    )

    return HuggingFacePipeline(pipeline=pipe)

# -------------------------------
# Sidebar - Men√∫ de navegaci√≥n
# -------------------------------
st.sidebar.title("üìå Men√∫ Principal")
menu = st.sidebar.radio(
    "Navegaci√≥n",
    ["üìÇ Cargar Datos", "üìä An√°lisis Exploratorio", "ü§ñ An√°lisis con LLM"]
)

# -------------------------------
# Guardar token en session_state
# -------------------------------
if "hf_token" not in st.session_state:
    st.session_state.hf_token = ""

hf_token_input = st.sidebar.text_input("üîë Ingresa tu Hugging Face Token", type="password")

# Si el usuario escribe un token nuevo, lo guardamos
if hf_token_input:
    st.session_state.hf_token = hf_token_input

# -------------------------------
# Cargar Datos
# -------------------------------
if "df" not in st.session_state:
    st.session_state.df = None

if menu == "üìÇ Cargar Datos":
    st.header("üìÇ Cargar Datos CSV")

    uploaded_file = st.file_uploader("Sube un archivo CSV", type=["csv"])
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)

            # Identificar columnas de fecha (solo si contienen "date" o "fecha" en el nombre)
            date_cols = [col for col in df.columns if "date" in col.lower() or "fecha" in col.lower()]
            for col in date_cols:
                try:
                    df[col] = pd.to_datetime(df[col], errors="coerce")
                except Exception:
                    pass

            st.session_state.df = df
            st.success("‚úÖ Datos cargados correctamente")
            st.dataframe(df.head())

        except Exception as e:
            st.error(f"‚ùå Error al leer el archivo: {e}")

# -------------------------------
# An√°lisis Exploratorio
# -------------------------------
elif menu == "üìä An√°lisis Exploratorio":
    st.header("üìä An√°lisis Exploratorio de Datos (EDA)")

    if st.session_state.df is not None:
        df = st.session_state.df

        st.subheader("üìã Informaci√≥n General")
        st.write(f"Filas: {df.shape[0]}, Columnas: {df.shape[1]}")
        st.write("Tipos de datos:")
        st.write(df.dtypes)

        st.subheader("üìâ Valores nulos")
        st.write(df.isnull().sum())

        st.subheader("üìà Estad√≠sticas descriptivas")
        st.write(df.describe(include="all"))

        # Visualizaci√≥n
        st.subheader("üìä Histogramas de variables num√©ricas")
        num_cols = df.select_dtypes(include=["int64", "float64"]).columns
        if len(num_cols) > 0:
            fig, axes = plt.subplots(len(num_cols), 1, figsize=(8, 4 * len(num_cols)))
            if len(num_cols) == 1:
                axes = [axes]
            for ax, col in zip(axes, num_cols):
                sns.histplot(df[col].dropna(), kde=True, ax=ax, color="skyblue")
                ax.set_title(f"Histograma de {col}")
            st.pyplot(fig)
        else:
            st.info("No hay columnas num√©ricas para graficar.")

    else:
        st.warning("‚ö†Ô∏è Primero carga un dataset en la secci√≥n 'üìÇ Cargar Datos'.")

# -------------------------------
# An√°lisis con LLM
# -------------------------------
elif menu == "ü§ñ An√°lisis con LLM":
    st.header("ü§ñ An√°lisis con LLM (Llama 3)")

    if st.session_state.df is not None and st.session_state.hf_token:
        df = st.session_state.df

        # Generar resumen simple del EDA para dar contexto al LLM
        resumen = f"""
        Este dataset tiene {df.shape[0]} filas y {df.shape[1]} columnas.
        Columnas: {list(df.columns)}.
        """

        # Inicializar LLM
        try:
            llm = build_llm(st.session_state.hf_token)
            st.success("‚úÖ LLM cargado correctamente")

            # Caja de preguntas
            pregunta = st.text_input("Escribe tu pregunta sobre los datos:")
            if st.button("Preguntar al LLM"):
                if pregunta:
                    prompt = f"""
                    El usuario tiene un dataset con el siguiente resumen:
                    {resumen}

                    Responde a la siguiente pregunta en espa√±ol, siendo claro y conciso:
                    {pregunta}
                    """
                    respuesta = llm.invoke(prompt)
                    st.subheader("üí° Respuesta del LLM")
                    st.write(respuesta)
        except Exception as e:
            st.error(f"‚ùå Error al inicializar el modelo: {e}")

    else:
        st.warning("‚ö†Ô∏è Debes cargar un dataset y escribir tu token de Hugging Face.")
