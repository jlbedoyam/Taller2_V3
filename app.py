import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from langchain_huggingface import HuggingFacePipeline

# -------------------- FunciÃ³n para inicializar el modelo LLM --------------------
def build_llm(hf_token: str):
    model_name = "meta-llama/Meta-Llama-3-8B-Instruct"

    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        use_auth_token=hf_token,
        device_map="auto",
        torch_dtype="auto"
    )

    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=512,
        temperature=0.2,
        top_p=0.9,
    )

    return HuggingFacePipeline(pipeline=pipe)


# -------------------- ConfiguraciÃ³n de la App --------------------
st.set_page_config(page_title="EDA + LLM", layout="wide")

st.title("ğŸ“Š ExploraciÃ³n de Datos con EDA + ğŸ¤– LLM")

menu = st.sidebar.radio("NavegaciÃ³n", ["ğŸ“‚ Carga de Datos", "ğŸ“ˆ AnÃ¡lisis EDA", "ğŸ¤– AnÃ¡lisis con LLM"])


# -------------------- ğŸ“‚ Carga de Datos --------------------
if menu == "ğŸ“‚ Carga de Datos":
    st.header("ğŸ“‚ Carga de Datos")

    uploaded_file = st.file_uploader("Sube un archivo CSV", type=["csv"])
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)

        # Convertir columnas que contienen "date" o "fecha" a formato datetime
        for col in df.columns:
            if "date" in col.lower() or "fecha" in col.lower():
                try:
                    df[col] = pd.to_datetime(df[col], errors="coerce")
                except:
                    pass

        st.session_state.df = df
        st.success("âœ… Datos cargados correctamente")

        st.subheader("Vista previa")
        st.dataframe(df.head())


# -------------------- ğŸ“ˆ AnÃ¡lisis EDA --------------------
elif menu == "ğŸ“ˆ AnÃ¡lisis EDA":
    st.header("ğŸ“ˆ AnÃ¡lisis Exploratorio de Datos")

    if "df" not in st.session_state:
        st.warning("Primero carga un dataset en la secciÃ³n ğŸ“‚ Carga de Datos")
    else:
        df = st.session_state.df

        st.subheader("InformaciÃ³n general")
        st.write(df.describe(include="all"))

        st.subheader("DistribuciÃ³n de variables numÃ©ricas")
        num_cols = df.select_dtypes(include=["float64", "int64"]).columns
        if len(num_cols) > 0:
            fig, ax = plt.subplots(figsize=(10, 5))
            df[num_cols].hist(ax=ax)
            st.pyplot(fig)

        st.subheader("Correlaciones")
        if len(num_cols) > 1:
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(df[num_cols].corr(), annot=True, cmap="coolwarm", ax=ax)
            st.pyplot(fig)


# -------------------- ğŸ¤– AnÃ¡lisis con LLM --------------------
elif menu == "ğŸ¤– AnÃ¡lisis con LLM":
    st.header("ğŸ¤– AnÃ¡lisis con LLM")

    if "df" not in st.session_state:
        st.warning("Primero carga un dataset en la secciÃ³n ğŸ“‚ Carga de Datos")
    else:
        if "hf_token" not in st.session_state:
            hf_token = st.text_input("ğŸ”‘ Ingresa tu Hugging Face Token", type="password")
            if hf_token:
                st.session_state.hf_token = hf_token
                st.success("âœ… Token guardado en sesiÃ³n")

        if "hf_token" in st.session_state:
            llm = build_llm(st.session_state.hf_token)

            st.subheader("Haz preguntas sobre tu dataset")
            question = st.text_input("â“ Escribe tu pregunta")
            if question:
                st.write("ğŸ’¡ Respuesta del modelo:")
                response = llm.invoke(question)
                st.write(response)
