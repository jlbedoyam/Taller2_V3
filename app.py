import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from langchain_huggingface import HuggingFacePipeline
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM

# -------------------------------
# ConfiguraciÃ³n general
# -------------------------------
st.set_page_config(
    page_title="Taller 2 - AnÃ¡lisis de Datos con LLM",
    layout="wide",
)

# -------------------------------
# FunciÃ³n para construir el LLM
# -------------------------------
def build_llm(hf_token: str):
    model_name = "meta-llama/Meta-Llama-3-8B-Instruct"

    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        use_auth_token=hf_token
    )
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        use_auth_token=hf_token,
        device_map="auto",
        torch_dtype="auto"
    )

    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=512,
        temperature=0.2,
        top_p=0.9,
    )

    return HuggingFacePipeline(pipeline=pipe)


    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=512,
        temperature=0.2,
        top_p=0.9,
    )

    return HuggingFacePipeline(pipeline=pipe)

# -------------------------------
# Sidebar - MenÃº de navegaciÃ³n
# -------------------------------
st.sidebar.title("ğŸ“Œ MenÃº Principal")
menu = st.sidebar.radio(
    "NavegaciÃ³n",
    ["ğŸ“‚ Cargar Datos", "ğŸ“Š AnÃ¡lisis Exploratorio", "ğŸ¤– AnÃ¡lisis con LLM"]
)

# -------------------------------
# Cargar Datos
# -------------------------------
if "df" not in st.session_state:
    st.session_state.df = None

if menu == "ğŸ“‚ Cargar Datos":
    st.header("ğŸ“‚ Cargar Datos CSV")

    uploaded_file = st.file_uploader("Sube un archivo CSV", type=["csv"])
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)

            # Identificar columnas de fecha
            date_cols = [col for col in df.columns if "date" in col.lower() or "fecha" in col.lower()]
            for col in date_cols:
                try:
                    df[col] = pd.to_datetime(df[col], errors="coerce")
                except Exception:
                    pass

            st.session_state.df = df
            st.success("âœ… Datos cargados correctamente")
            st.dataframe(df.head())

        except Exception as e:
            st.error(f"âŒ Error al leer el archivo: {e}")

# -------------------------------
# AnÃ¡lisis Exploratorio
# -------------------------------
elif menu == "ğŸ“Š AnÃ¡lisis Exploratorio":
    st.header("ğŸ“Š AnÃ¡lisis Exploratorio de Datos (EDA)")

    if st.session_state.df is not None:
        df = st.session_state.df

        st.subheader("ğŸ“‹ InformaciÃ³n General")
        st.write(f"Filas: {df.shape[0]}, Columnas: {df.shape[1]}")
        st.write("Tipos de datos:")
        st.write(df.dtypes)

        st.subheader("ğŸ“‰ Valores nulos")
        st.write(df.isnull().sum())

        st.subheader("ğŸ“ˆ EstadÃ­sticas descriptivas")
        st.write(df.describe(include="all"))

        # VisualizaciÃ³n
        st.subheader("ğŸ“Š Histogramas de variables numÃ©ricas")
        num_cols = df.select_dtypes(include=["int64", "float64"]).columns
        if len(num_cols) > 0:
            fig, axes = plt.subplots(len(num_cols), 1, figsize=(8, 4 * len(num_cols)))
            if len(num_cols) == 1:
                axes = [axes]
            for ax, col in zip(axes, num_cols):
                sns.histplot(df[col].dropna(), kde=True, ax=ax, color="skyblue")
                ax.set_title(f"Histograma de {col}")
            st.pyplot(fig)
        else:
            st.info("No hay columnas numÃ©ricas para graficar.")

    else:
        st.warning("âš ï¸ Primero carga un dataset en la secciÃ³n 'ğŸ“‚ Cargar Datos'.")

# -------------------------------
# AnÃ¡lisis con LLM
# -------------------------------
elif menu == "ğŸ¤– AnÃ¡lisis con LLM":
    st.header("ğŸ¤– AnÃ¡lisis con LLM (Llama 3)")

    if st.session_state.df is None:
        st.warning("âš ï¸ Primero carga un dataset en la secciÃ³n 'ğŸ“‚ Cargar Datos'.")
    else:
        # Pedimos token SOLO aquÃ­
        if "hf_token" not in st.session_state or not st.session_state.hf_token:
            hf_token_input = st.text_input("ğŸ”‘ Ingresa tu Hugging Face Token", type="password")
            if hf_token_input:
                st.session_state.hf_token = hf_token_input
                st.success("âœ… Token guardado para toda la sesiÃ³n. Ahora ya puedes usar el modelo.")
                st.stop()
            else:
                st.info("â„¹ï¸ Ingresa tu token para continuar.")
                st.stop()

        # Ya tenemos token y dataset
        try:
            llm = build_llm(st.session_state.hf_token)
            st.success("âœ… LLM cargado correctamente")

            df = st.session_state.df
            resumen = f"""
            Este dataset tiene {df.shape[0]} filas y {df.shape[1]} columnas.
            Columnas: {list(df.columns)}.
            """

            pregunta = st.text_input("Escribe tu pregunta sobre los datos:")
            if st.button("Preguntar al LLM"):
                if pregunta:
                    prompt = f"""
                    El usuario tiene un dataset con el siguiente resumen:
                    {resumen}

                    Responde a la siguiente pregunta en espaÃ±ol, siendo claro y conciso:
                    {pregunta}
                    """
                    respuesta = llm.invoke(prompt)
                    st.subheader("ğŸ’¡ Respuesta del LLM")
                    st.write(respuesta)
        except Exception as e:
            st.error(f"âŒ Error al inicializar el modelo: {e}")
